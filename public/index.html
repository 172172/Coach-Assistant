<!DOCTYPE html>
<html lang="sv">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Coach Assistant</title>
  <link rel="icon" href="data:,">
  <style>
    :root { --bg:#111; --fg:#fff; --acc:#00aaff; --mut:#bbb; }
    body { font-family: system-ui, sans-serif; padding: 2rem; background: var(--bg); color: var(--fg); }
    .row { display:flex; gap:1rem; align-items:center; flex-wrap:wrap; }
    button { padding: .9rem 1.2rem; font-size: 1rem; cursor: pointer; border: none; border-radius: 10px; background: var(--acc); color:#fff; }
    #output { margin-top: 1rem; font-size: 1.05rem; }
    .status { font-size: .95rem; color: #ddd }
    .pill { background:#1a1a1a; border:1px solid #333; padding:.7rem .9rem; border-radius:10px; margin-top:.6rem }
    .muted { color: var(--mut); font-size:.95rem }
    .dot { width:10px; height:10px; border-radius:50%; display:inline-block; margin-right:.5rem; vertical-align:middle }
    .listen { background:#22c55e } .think { background:#facc15 } .speak { background:#60a5fa } .idle { background:#6b7280 }
  </style>
</head>
<body>
  <h1>Coach Assistant</h1>
  <p class="muted">Tryck start en gång. Prata → bli tyst så svarar den. Börja prata för att avbryta.</p>

  <div class="row">
    <button id="startBtn">▶️ Starta röstloop</button>
    <button id="stopBtn" style="background:#ef4444;display:none">⏹️ Stoppa</button>
    <span id="recStatus" class="status"><span class="dot idle"></span>Redo</span>
  </div>

  <div id="output"></div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn  = document.getElementById('stopBtn');
    const output   = document.getElementById('output');
    const recStatus= document.getElementById('recStatus');

    let state = 'IDLE';
    let running = false;

    // Mic & VAD
    let micStream = null, mediaRecorder = null, chunks = [];
    let vadInterval = null, audioCtxVAD = null, analyser = null, vadData = null;

    // TTS
    let ttsCtx = null, ttsSource = null;

    // VAD/Barge in – trösklar
    const SILENCE_THRESHOLD = 12;
    const SILENCE_HOLD_MS   = 900;
    const MAX_RECORD_MS     = 12000;

    // Barge-in: kräver tydligt starkare nivå än TTS-läckage
    let speakBaseline = 0;
    const BARGE_MARGIN_DB   = 18;   // hur mycket över baseline som krävs
    const BARGE_HOLD_MS     = 500;  // håll kvar över tröskel så här länge
    let bargeHold = 0;

    function setStatus(mode, text) {
      const dotClass = mode === 'LISTENING' ? 'listen' : mode === 'THINKING' ? 'think' : mode === 'SPEAKING' ? 'speak' : 'idle';
      recStatus.innerHTML = `<span class="dot ${dotClass}"></span>${text}`;
    }

    // ---------- TTS ----------
    function stopTTS() {
      try { ttsSource && ttsSource.stop(); } catch {}
      ttsSource = null;
      if (ttsCtx) { try { ttsCtx.close(); } catch {} }
      ttsCtx = null;
    }

    async function speak(text) {
      stopTTS();
      state = 'SPEAKING';
      setStatus(state, 'Svarar… (börja prata för att avbryta)');

      try {
        const res = await fetch('/api/tts', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text })
        });
        if (!res.ok) throw new Error('Fel vid TTS-svar');

        const blob = await res.blob();
        const arrayBuffer = await blob.arrayBuffer();

        ttsCtx = new (window.AudioContext || window.webkitAudioContext)();
        const gainNode = ttsCtx.createGain();
        gainNode.gain.value = 2.0;

        ttsSource = ttsCtx.createBufferSource();
        const audioBuffer = await ttsCtx.decodeAudioData(arrayBuffer);
        ttsSource.buffer = audioBuffer;
        ttsSource.connect(gainNode).connect(ttsCtx.destination);
        ttsSource.onended = () => { if (running) startListening(); };
        ttsSource.start(0);

        // initiera baseline så barge-in inte triggas av TTS-läckage
        speakBaseline = 0;
        bargeHold = 0;
      } catch (err) {
        console.error('TTS-fel:', err);
        output.insertAdjacentHTML('beforeend', "<div class='pill'>Kunde inte spela upp ljud.</div>");
        if (running) startListening();
      }
    }

    // ---------- CHAT ----------
    async function askAssistant(text) {
      state = 'THINKING';
      setStatus(state, 'Bearbetar…');
      output.insertAdjacentHTML('beforeend', `<div class="pill"><strong>Du sa:</strong> ${text}</div>`);

      try {
        const res = await fetch('/api/chat', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ message: text })
        });
        const data = await res.json();
        if (!res.ok) throw new Error(data?.error || 'Chat-fel');

        const answer = (typeof data.reply === 'string') ? data.reply
                      : data.reply?.reply || 'Jag kunde inte formulera ett svar.';
        output.insertAdjacentHTML('beforeend', `<div class="pill"><strong>Svar:</strong><br>${answer}</div>`);
        await speak(answer);
      } catch (err) {
        console.error('Chat-fel:', err);
        output.insertAdjacentHTML('beforeend', `<div class="pill">Kunde inte få svar från AI.</div>`);
        if (running) startListening();
      }
    }

    // ---------- WHISPER ----------
    async function transcribe(blob) {
      const formData = new FormData();
      formData.append('audio', blob, 'audio.webm');
      const res = await fetch('/api/whisper', { method: 'POST', body: formData });
      const data = await res.json();
      if (!res.ok) throw new Error(data?.error || 'Transkriberingsfel');
      return (data.text || '').trim();
    }

    // ---------- VAD utils ----------
    function rmsLevel(uint8PCM) {
      let sum = 0;
      for (let i = 0; i < uint8PCM.length; i++) { const v = uint8PCM[i] - 128; sum += v * v; }
      const rms = Math.sqrt(sum / uint8PCM.length);
      return Math.min(255, Math.max(0, Math.round(rms * 6)));
    }

    // ---------- LISTENING ----------
    async function startListening() {
      if (!running) return;
      stopTTS();
      state = 'LISTENING';
      setStatus(state, 'Lyssnar… (bli tyst för att skicka)');

      chunks = [];
      const startedAt = performance.now();
      let silentMs = 0;

      mediaRecorder = new MediaRecorder(micStream, { mimeType: 'audio/webm' });
      mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) chunks.push(e.data); };
      mediaRecorder.onstop = async () => {
        clearInterval(vadInterval);
        const blob = new Blob(chunks, { type: 'audio/webm' });
        if (!running) return;
        try {
          const text = await transcribe(blob);
          if (text) await askAssistant(text);
          else {
            output.insertAdjacentHTML('beforeend', "<div class='pill'>Hörde inget tydligt. Prova igen.</div>");
            if (running) startListening();
          }
        } catch (err) {
          console.error('Whisper-fel:', err);
          output.insertAdjacentHTML('beforeend', "<div class='pill'>Kunde inte transkribera ljudet.</div>");
          if (running) startListening();
        }
      };
      mediaRecorder.start();

      vadInterval = setInterval(() => {
        analyser.getByteTimeDomainData(vadData);
        const level = rmsLevel(vadData);

        // auto-stop vid tystnad eller timeout
        if (level < SILENCE_THRESHOLD) silentMs += 100; else silentMs = 0;
        if (silentMs >= SILENCE_HOLD_MS || performance.now() - startedAt > MAX_RECORD_MS) {
          try { mediaRecorder.state !== 'inactive' && mediaRecorder.stop(); } catch {}
        }

        // barge-in: räkna baseline av TTS-läckage och kräv tydligt högre nivå
        if (state === 'SPEAKING') {
          speakBaseline = speakBaseline ? (0.9 * speakBaseline + 0.1 * level) : level;
          if (level > speakBaseline + BARGE_MARGIN_DB) {
            bargeHold += 100;
            if (bargeHold >= BARGE_HOLD_MS) {
              stopTTS(); // låt lyssningen fortsätta
              bargeHold = 0;
            }
          } else {
            bargeHold = 0;
          }
        }
      }, 100);
    }

    // ---------- START / STOP ----------
    async function startLoop() {
      if (running) return;
      running = true;
      startBtn.style.display = 'none';
      stopBtn.style.display = 'inline-block';

      try {
        micStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: false
          }
        });
      } catch (e) {
        output.insertAdjacentHTML('beforeend', "<div class='pill'>Mikrofon kunde inte startas (behörighet?).</div>");
        running = false;
        startBtn.style.display = 'inline-block';
        stopBtn.style.display  = 'none';
        return;
      }

      audioCtxVAD = new (window.AudioContext || window.webkitAudioContext)();
      const src = audioCtxVAD.createMediaStreamSource(micStream);
      analyser = audioCtxVAD.createAnalyser();
      analyser.fftSize = 2048;
      vadData = new Uint8Array(analyser.fftSize);
      src.connect(analyser);

      startListening();
    }

    function stopLoop() {
      running = false;
      state = 'IDLE';
      setStatus(state, 'Stoppad');
      startBtn.style.display = 'inline-block';
      stopBtn.style.display  = 'none';

      stopTTS();
      try { mediaRecorder && mediaRecorder.state !== 'inactive' && mediaRecorder.stop(); } catch {}
      if (vadInterval) { clearInterval(vadInterval); vadInterval = null; }
      try { analyser && analyser.disconnect(); } catch {}
      try { audioCtxVAD && audioCtxVAD.close(); } catch {}
      analyser = null; audioCtxVAD = null; vadData = null;

      if (micStream) { micStream.getTracks().forEach(t => t.stop()); micStream = null; }
    }

    startBtn.addEventListener('click', startLoop);
    stopBtn.addEventListener('click', stopLoop);
    window.addEventListener('keydown', (e) => { if (e.key === 'Escape') stopLoop(); });
  </script>
</body>
</html>
