<!DOCTYPE html>
<html lang="sv">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Coach Assistant</title>
  <link rel="icon" href="data:,"><!-- tysta favicon 404 -->
  <style>
    :root { --bg:#111; --fg:#fff; --acc:#00aaff; --mut:#bbb; }
    body { font-family: system-ui, sans-serif; padding: 2rem; background: var(--bg); color: var(--fg); }
    .row { display:flex; gap:1rem; align-items:center; flex-wrap:wrap; }
    button, select { padding: .9rem 1.1rem; font-size: 1rem; cursor: pointer; border: none; border-radius: 10px; }
    button { background: var(--acc); color: #fff; }
    select { background:#1a1a1a; border:1px solid #333; color:#fff }
    #output { margin-top: 1.25rem; font-size: 1.05rem; }
    .muted { color: var(--mut); font-size:.95rem }
    .pill { background:#1a1a1a; border:1px solid #333; padding:.7rem .9rem; border-radius:10px; margin-top:.6rem }
    .tag { display:inline-block; padding:.1rem .45rem; border:1px solid #333; border-radius:6px; margin-left:.5rem; font-size:.8rem; color:#ddd }
    .status { margin-left:.5rem; font-size:.95rem; color:#ddd }
    .ok { color:#6ee7a8 } .warn { color:#fbbf24 } .err { color:#f87171 }
  </style>
</head>
<body>
  <h1>Coach Assistant</h1>
  <p class="muted">Klicka och prata naturligt. S√§g <em>‚Äún√§sta‚Äù</em>, <em>‚Äúf√∂rklara (steg X)‚Äù</em> eller <em>‚Äúupprepa‚Äù</em> f√∂r guidat l√§ge.</p>

  <div class="row">
    <button id="micBtn">üé§ Starta r√∂st</button>
    <span id="recStatus" class="status"></span>
    <label>
      L√§ge:
      <select id="mode">
        <option value="pedagogiskt" selected>Pedagogiskt (steg-f√∂r-steg)</option>
        <option value="snabbt">Snabbt svar</option>
      </select>
    </label>
  </div>

  <div id="output"></div>

  <script>
    const micBtn = document.getElementById('micBtn');
    const output = document.getElementById('output');
    const recStatus = document.getElementById('recStatus');
    const modeSel = document.getElementById('mode');

    // Samtalsminne i klienten (skickas till backend)
    const history = []; // {role:'user'|'assistant', content:string}
    let pendingSteps = []; // senaste AI:ns steglista
    let stepCursor = 0;

    // ---------- TTS (ElevenLabs via /api/tts) med avbrott ----------
    let activeAudioCtx = null;
    let activeSource = null;
    function stopTTS() {
      try { activeSource && activeSource.stop(); } catch {}
      activeSource = null;
      if (activeAudioCtx) { try { activeAudioCtx.close(); } catch {} }
      activeAudioCtx = null;
    }

    const speak = async (text) => {
      try {
        stopTTS(); // avbryt ev. p√•g√•ende tal
        const res = await fetch('/api/tts', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text })
        });
        if (!res.ok) throw new Error("Fel vid TTS-svar");
        const blob = await res.blob();
        const arrayBuffer = await blob.arrayBuffer();

        activeAudioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const gainNode = activeAudioCtx.createGain();
        gainNode.gain.value = 2.0;

        activeSource = activeAudioCtx.createBufferSource();
        const audioBuffer = await activeAudioCtx.decodeAudioData(arrayBuffer);
        activeSource.buffer = audioBuffer;
        activeSource.connect(gainNode).connect(activeAudioCtx.destination);
        activeSource.start(0);
      } catch (err) {
        console.error("TTS-fel:", err);
        output.insertAdjacentHTML("beforeend", "<div class='err'>Kunde inte spela upp ljud.</div>");
      }
    };

    // ---------- Sm√• normaliseringar (stavfel/fels√§gningar) ----------
    function normalizeTranscript(t) {
      const map = [
        [/sockerbit/gi, "sortbyte"],
        [/co2/gi, "koldioxid"],
        [/cip/gi, "CIP"], [/ocme/gi, "OCME"], [/rco/gi, "RCO"],
        [/kl\s*(\d+)/gi, "klockan $1"]
      ];
      let out = (t || "").trim();
      map.forEach(([re, repl]) => { out = out.replace(re, repl); });
      return out;
    }

    // ---------- Skicka till backend-chat med historia ----------
    async function callChat(message, opts={}) {
      const body = {
        message,
        mode: modeSel.value,
        history: history.slice(-8),        // skicka senaste kontexten
        explainStepIndex: opts.explainStepIndex ?? null,
        lastSteps: pendingSteps.length ? pendingSteps : null
      };

      const res = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(body)
      });
      const data = await res.json();
      if (!res.ok) throw new Error(data?.error || "Chat-fel");

      // F√∂rs√∂k tolka strukturerat svar
      let replyText = "";
      let steps = null;
      try {
        const parsed = typeof data.reply === "string" ? JSON.parse(data.reply) : data.reply;
        replyText = parsed.reply || "";
        steps = Array.isArray(parsed.steps) ? parsed.steps : null;
      } catch {
        // Fallback: allt √§r bara text
        replyText = data.reply;
      }

      // Rendera och lagra
      output.insertAdjacentHTML("beforeend", `<div class="pill"><strong>Svar:</strong><br>${replyText}</div>`);
      history.push({ role: "assistant", content: replyText });

      // Spara steglista f√∂r ‚Äún√§sta‚Äù
      if (steps && steps.length) {
        pendingSteps = steps;
        stepCursor = 0;
        output.insertAdjacentHTML("beforeend", `<div class="muted">Jag har ${steps.length} steg redo. S√§g ‚Äún√§sta‚Äù f√∂r att g√• vidare.</div>`);
      }

      // Talsyntes
      speak(replyText);
    }

    // ---------- Kommandohantering (n√§sta/f√∂rklara/upprepa) ----------
    function isNextCmd(t) {
      return /\b(n√§sta|forts√§tt|vidare)\b/i.test(t);
    }
    function isRepeatCmd(t) {
      return /\b(upprepa|igen)\b/i.test(t);
    }
    function extractExplainIndex(t) {
      // ‚Äúf√∂rklara steg 2‚Äù ‚Üí 2 (0-baserat senare)
      const m = t.match(/f√∂rklara(?:\s+steg)?\s+(\d+)/i);
      if (m) return Math.max(1, parseInt(m[1], 10));
      return null;
    }
    function isExplainGeneral(t) {
      return /\bf√∂rklara\b/i.test(t);
    }

    async function handleCommand(heard) {
      const text = normalizeTranscript(heard);

      // Lokala kommandon f√∂r pending steps
      if (pendingSteps.length) {
        if (isNextCmd(text)) {
          if (stepCursor < pendingSteps.length) {
            const step = pendingSteps[stepCursor++];
            output.insertAdjacentHTML("beforeend", `<div class="pill"><strong>Steg ${stepCursor}:</strong> ${step}</div>`);
            history.push({ role: "assistant", content: `Steg ${stepCursor}: ${step}` });
            speak(`Steg ${stepCursor}: ${step}`);
            if (stepCursor >= pendingSteps.length) {
              output.insertAdjacentHTML("beforeend", `<div class="muted">Det var sista steget.</div>`);
            } else {
              output.insertAdjacentHTML("beforeend", `<div class="muted">S√§g ‚Äún√§sta‚Äù f√∂r att forts√§tta.</div>`);
            }
            return;
          }
        }
        if (isRepeatCmd(text)) {
          const idx = Math.max(0, stepCursor - 1);
          const step = pendingSteps[idx];
          speak(`Upprepar steg ${idx + 1}: ${step}`);
          output.insertAdjacentHTML("beforeend", `<div class="muted">Upprepar steg ${idx + 1}.</div>`);
          return;
        }
        const explicit = extractExplainIndex(text);
        if (explicit !== null) {
          const idx = explicit - 1;
          if (idx >= 0 && idx < pendingSteps.length) {
            // Be backend f√∂rklara just detta steg
            await callChat(`F√∂rklara steg ${explicit} mer ing√•ende.`, { explainStepIndex: idx });
            return;
          }
        }
        if (isExplainGeneral(text)) {
          // F√∂rklara senaste steg
          const idx = Math.max(0, stepCursor - 1);
          await callChat(`F√∂rklara steg ${idx + 1} mer ing√•ende.`, { explainStepIndex: idx });
          return;
        }
      }

      // Vanlig fr√•ga ‚Üí skicka till modellen
      output.insertAdjacentHTML("beforeend", `<div class="pill"><strong>Du sa:</strong> ${text} <span class="tag">Whisper</span></div>`);
      history.push({ role: "user", content: text });
      await callChat(text);
    }

    // ---------- Inspelning med automatisk tystnads-stop ----------
    const startRecording = async () => {
      try {
        stopTTS(); // avbryt tal n√§r vi b√∂rjar lyssna
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recStatus.textContent = "Lyssnar‚Ä¶ (bli tyst f√∂r att stoppa)";
        micBtn.disabled = true;

        const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
        const chunks = [];
        mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) chunks.push(e.data); };

        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const sourceNode = audioCtx.createMediaStreamSource(stream);
        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        sourceNode.connect(analyser);
        const data = new Uint8Array(analyser.fftSize);

        let silentMs = 0;
        const SILENCE_THRESHOLD = 12; // 0-255
        const SILENCE_HOLD_MS = 900;
        const MAX_RECORD_MS = 10000;
        const startedAt = performance.now();

        const vadInterval = setInterval(() => {
          analyser.getByteTimeDomainData(data);
          let sum = 0;
          for (let i = 0; i < data.length; i++) { const v = data[i] - 128; sum += v * v; }
          const rms = Math.sqrt(sum / data.length);
          const level = Math.min(255, Math.max(0, Math.round(rms * 6)));

          silentMs = (level < SILENCE_THRESHOLD) ? (silentMs + 100) : 0;
          if (silentMs >= SILENCE_HOLD_MS || performance.now() - startedAt > MAX_RECORD_MS) {
            clearInterval(vadInterval);
            try { mediaRecorder.state !== "inactive" && mediaRecorder.stop(); } catch {}
          }
        }, 100);

        mediaRecorder.onstop = async () => {
          try { sourceNode.disconnect(); analyser.disconnect(); audioCtx.close(); } catch {}
          stream.getTracks().forEach(t => t.stop());
          recStatus.textContent = "Bearbetar‚Ä¶";

          const blob = new Blob(chunks, { type: 'audio/webm' });
          const formData = new FormData();
          formData.append('audio', blob, 'audio.webm');

          try {
            const res = await fetch('/api/whisper', { method: 'POST', body: formData });
            const data = await res.json();

            if (res.ok && data.text) {
              await handleCommand(data.text);
            } else {
              console.error("Transkriberingsfel:", data);
              output.insertAdjacentHTML("beforeend", "<div class='err'>Kunde inte transkribera ljudet.</div>");
            }
          } catch (err) {
            console.error("Fetch-fel:", err);
            output.insertAdjacentHTML("beforeend", "<div class='err'>Fel vid kontakt med servern.</div>");
          } finally {
            recStatus.textContent = "";
            micBtn.disabled = false;
          }
        };

        mediaRecorder.start();
      } catch (err) {
        console.error("Mikrofonfel:", err);
        output.insertAdjacentHTML("beforeend", "<div class='err'>Mikrofon kunde inte startas.</div>");
      }
    };

    micBtn.addEventListener('click', startRecording);
  </script>
</body>
</html>
