<!DOCTYPE html>
<html lang="sv">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Coach Assistant</title>
  <style>
    body {
      font-family: sans-serif;
      padding: 2rem;
      background: #111;
      color: #fff;
    }
    button {
      padding: 1rem;
      font-size: 1.2rem;
      cursor: pointer;
      background: #00aaff;
      color: #fff;
      border: none;
      border-radius: 8px;
      margin-top: 1rem;
    }
    #output {
      margin-top: 2rem;
      font-size: 1.2rem;
    }
  </style>
</head>
<body>
  <h1>Coach Assistant</h1>
  <p>Klicka p친 mikrofonen och st칛ll en fr친ga, t.ex: <em>"Hur g칬r jag ett sortbyte i tappen?"</em></p>
  <button id="micBtn">游꿗 Starta r칬st</button>
  <div id="output"></div>

  <script>
    const micBtn = document.getElementById('micBtn');
    const output = document.getElementById('output');

    const speak = async (text) => {
      try {
        const res = await fetch('/api/tts', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text })
        });

        if (!res.ok) throw new Error("Fel vid TTS-svar");

        const blob = await res.blob();
        const arrayBuffer = await blob.arrayBuffer();

        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 2.0;

        const source = audioContext.createBufferSource();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        source.buffer = audioBuffer;
        source.connect(gainNode).connect(audioContext.destination);
        source.start(0);
      } catch (err) {
        console.error("TTS-fel:", err);
        output.innerHTML += "<br><span style='color:red'>Kunde inte spela upp ljud.</span>";
      }
    };

    const sendToChatGPT = async (text) => {
      output.innerHTML = "<strong>Du fr친gade:</strong> " + text + "<br><em>V칛ntar p친 svar...</em>";

      try {
        const response = await fetch("/api/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: text })
        });

        const data = await response.json();
        const answer = data.reply;
        output.innerHTML += "<br><strong>Svar:</strong> " + answer;
        speak(answer);
      } catch (err) {
        console.error("ChatGPT-fel:", err);
        output.innerHTML += "<br><span style='color:red'>Kunde inte f친 svar fr친n AI.</span>";
      }
    };

    const startRecording = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      const chunks = [];

      mediaRecorder.ondataavailable = (e) => {
        chunks.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'audio/webm' });
        const formData = new FormData();
        formData.append('audio', blob, 'audio.webm');

        try {
          const res = await fetch('/api/whisper', {
            method: 'POST',
            body: formData
          });

          const data = await res.json();

          if (res.ok && data.text) {
            sendToChatGPT(data.text);
          } else {
            console.error("Transkriberingsfel:", data);
            output.innerHTML += "<br><span style='color:red'>Kunde inte transkribera ljudet.</span>";
          }
        } catch (err) {
          console.error("Fetch-fel:", err);
          output.innerHTML += "<br><span style='color:red'>Fel vid kontakt med servern.</span>";
        }
      };

      mediaRecorder.start();
      setTimeout(() => mediaRecorder.stop(), 4000);
    };

    micBtn.addEventListener('click', startRecording);
  </script>
</body>
</html>
